<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Realtime Dictation + Speech Analytics</title>
  <style>
    :root{
      --bg:#0b0f14;
      --panel:#121924;
      --panel2:#0f1520;
      --text:#e8eef6;
      --muted:#a9b7c6;
      --accent:#66e3a3;
      --warn:#ffd166;
      --bad:#ff5d6c;
      --line:#223044;
      --chip:#1a2433;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
    }
    *{box-sizing:border-box}
    body{
      margin:0;
      background: radial-gradient(1200px 700px at 20% 10%, #132033 0%, var(--bg) 60%);
      color:var(--text);
      font-family:var(--sans);
      line-height:1.35;
    }
    header{
      padding:20px 18px 10px;
      max-width:1200px;
      margin:0 auto;
    }
    header h1{
      margin:0 0 6px;
      font-size:18px;
      font-weight:700;
      letter-spacing:.2px;
    }
    header p{
      margin:0;
      color:var(--muted);
      font-size:13px;
    }
    main{
      max-width:1200px;
      margin:0 auto;
      padding:12px 18px 22px;
      display:grid;
      grid-template-columns: 1.05fr .95fr;
      gap:14px;
    }
    .card{
      background: linear-gradient(180deg, rgba(255,255,255,.03), rgba(255,255,255,.01));
      border:1px solid var(--line);
      border-radius:16px;
      padding:14px;
      box-shadow: 0 10px 30px rgba(0,0,0,.25);
    }
    .row{
      display:flex;
      gap:10px;
      flex-wrap:wrap;
      align-items:center;
    }
    button{
      border:1px solid var(--line);
      background: #0f1724;
      color:var(--text);
      padding:9px 12px;
      border-radius:12px;
      cursor:pointer;
      font-weight:600;
      font-size:13px;
    }
    button:hover{border-color:#33507a}
    button.primary{
      background: linear-gradient(180deg, rgba(102,227,163,.18), rgba(102,227,163,.06));
      border-color: rgba(102,227,163,.45);
    }
    button.danger{
      background: linear-gradient(180deg, rgba(255,93,108,.18), rgba(255,93,108,.06));
      border-color: rgba(255,93,108,.45);
    }
    button:disabled{opacity:.5; cursor:not-allowed;}
    select, input[type="number"]{
      background: var(--panel2);
      color:var(--text);
      border:1px solid var(--line);
      border-radius:12px;
      padding:8px 10px;
      font-size:13px;
      outline:none;
    }
    label{
      color:var(--muted);
      font-size:12px;
      display:flex;
      align-items:center;
      gap:8px;
    }
    textarea{
      width:100%;
      min-height:220px;
      resize:vertical;
      background: rgba(15,21,32,.55);
      border:1px solid var(--line);
      border-radius:14px;
      color:var(--text);
      padding:12px;
      font-size:13px;
      outline:none;
    }
    .small{ font-size:12px; color:var(--muted); }
    .mono{ font-family:var(--mono); }
    .hr{ height:1px; background:var(--line); margin:12px 0; }
    .badge{
      display:inline-flex;
      gap:6px;
      align-items:center;
      background: var(--chip);
      border:1px solid var(--line);
      border-radius:999px;
      padding:6px 10px;
      font-size:12px;
      color:var(--muted);
      font-family:var(--mono);
    }
    .dot{
      width:9px;height:9px;border-radius:50%;
      background: #3b4c67;
      box-shadow: 0 0 0 2px rgba(0,0,0,.25);
    }
    .dot.on{ background: var(--accent); box-shadow:0 0 16px rgba(102,227,163,.5); }
    .dot.warn{ background: var(--warn); box-shadow:0 0 16px rgba(255,209,102,.35); }
    .dot.bad{ background: var(--bad); box-shadow:0 0 16px rgba(255,93,108,.35); }

    .grid{
      display:grid;
      grid-template-columns: repeat(2, 1fr);
      gap:10px;
      margin-top:12px;
    }
    .metric{
      background: rgba(15,21,32,.55);
      border:1px solid var(--line);
      border-radius:14px;
      padding:10px;
      min-height:86px;
    }
    .metric .k{ color:var(--muted); font-size:12px; margin-bottom:6px; }
    .metric .v{ font-family:var(--mono); font-size:18px; font-weight:800; }
    .metric .s{ color:var(--muted); font-size:12px; margin-top:6px; }

    .viz{
      margin-top:10px;
      display:grid;
      grid-template-columns: 1fr;
      gap:10px;
    }
    .bar{
      height:10px;
      background:#0e1521;
      border:1px solid var(--line);
      border-radius:999px;
      overflow:hidden;
    }
    .bar > div{
      height:100%;
      width:0%;
      background: linear-gradient(90deg, rgba(102,227,163,.9), rgba(102,227,163,.35));
      transition: width .08s linear;
    }
    .panelTitle{
      font-size:12px;
      color:var(--muted);
      margin-bottom:8px;
    }

    table{
      width:100%;
      border-collapse:separate;
      border-spacing:0;
      overflow:hidden;
      border-radius:14px;
      border:1px solid var(--line);
      background: rgba(15,21,32,.55);
    }
    th, td{
      padding:8px 10px;
      font-size:12px;
      color:var(--text);
      border-bottom:1px solid rgba(34,48,68,.65);
      vertical-align:top;
    }
    th{
      color:var(--muted);
      font-weight:700;
      background: rgba(18,25,36,.65);
      position:sticky;
      top:0;
      z-index:1;
    }
    tr:last-child td{border-bottom:none}
    .scroll{
      max-height:260px;
      overflow:auto;
      border-radius:14px;
    }

    .hist{
      display:grid;
      gap:8px;
    }
    .histRow{
      display:grid;
      grid-template-columns: 110px 1fr 50px;
      align-items:center;
      gap:10px;
    }
    .histBar{
      height:10px;
      border:1px solid var(--line);
      border-radius:999px;
      overflow:hidden;
      background:#0e1521;
    }
    .histBar > div{
      height:100%;
      width:0%;
      background: linear-gradient(90deg, rgba(255,209,102,.85), rgba(255,209,102,.25));
      transition: width .15s ease;
    }

    .footer{
      max-width:1200px;
      margin:0 auto;
      padding:0 18px 22px;
      color:var(--muted);
      font-size:12px;
    }

    @media (max-width: 1020px){
      main{grid-template-columns:1fr}
    }
  </style>
</head>

<body>
<header>
  <h1>Realtime Dictation + Speech Analytics</h1>
  <p>
    Browser-only: <span class="mono">Web Speech API</span> (transcription) + <span class="mono">Web Audio API</span> (signal metrics).
    Includes per-utterance segmentation, rolling WPM, pause distribution, and real-time total silence time.
  </p>
</header>

<main>
  <!-- LEFT -->
  <section class="card">
    <div class="row" style="justify-content:space-between">
      <div class="row">
        <button id="btnStart" class="primary">Start</button>
        <button id="btnStop" class="danger" disabled>Stop</button>
        <button id="btnReset">Reset</button>
        <span class="badge"><span id="statusDot" class="dot"></span><span id="statusText">idle</span></span>
      </div>

      <div class="row">
        <label>
          Language
          <select id="lang">
            <option value="en-US">en-US</option>
            <option value="en-GB">en-GB</option>
            <option value="fi-FI">fi-FI</option>
            <option value="ja-JP">ja-JP</option>
            <option value="vi-VN">vi-VN</option>
          </select>
        </label>

        <label>
          Silence threshold
          <input id="silenceDb" type="number" value="-45" step="1" style="width:80px"/>
          <span class="small">dB</span>
        </label>

        <label>
          Min pause
          <input id="minPauseMs" type="number" value="300" step="50" style="width:80px"/>
          <span class="small">ms</span>
        </label>

        <label>
          Rolling WPM window
          <input id="rollWinSec" type="number" value="10" step="1" style="width:70px"/>
          <span class="small">s</span>
        </label>
      </div>
    </div>

    <div class="hr"></div>

    <label class="small" style="margin-bottom:6px; display:block;">Transcript (final + interim)</label>
    <textarea id="transcript" placeholder="Your speech transcript will appear here..." spellcheck="false"></textarea>

    <div class="viz">
      <div>
        <div class="row" style="justify-content:space-between">
          <div class="small">Live volume (RMS → dBFS-ish)</div>
          <div class="small mono"><span id="volDb">—</span> dB</div>
        </div>
        <div class="bar"><div id="volBar"></div></div>
      </div>

      <div>
        <div class="row" style="justify-content:space-between">
          <div class="small">Live pitch (autocorrelation, best-effort)</div>
          <div class="small mono"><span id="pitchHz">—</span> Hz</div>
        </div>
        <div class="bar"><div id="pitchBar"></div></div>
      </div>

      <div>
        <div class="row" style="justify-content:space-between">
          <div class="small">Rolling speaking rate (windowed)</div>
          <div class="small mono"><span id="rollingWpm">0</span> WPM</div>
        </div>
        <div class="bar"><div id="rollBar"></div></div>
      </div>

      <div class="small">
        Notes: “tone” is approximated via pitch statistics; robust prosody/emotion inference requires dedicated models.
        Utterances are segmented by detected pauses (silence threshold + min pause).
      </div>
    </div>
  </section>

  <!-- RIGHT -->
  <aside class="card">
    <div class="row" style="justify-content:space-between; align-items:flex-end;">
      <div>
        <div class="small">Session</div>
        <div class="mono" style="font-size:18px; font-weight:900"><span id="elapsed">00:00.0</span></div>
      </div>
      <div class="small">Pause = silence ≥ min pause.</div>
    </div>

    <div class="grid" aria-label="metrics grid">
      <div class="metric">
        <div class="k">Total words (final)</div>
        <div class="v" id="words">0</div>
        <div class="s">Final transcript tokens</div>
      </div>

      <div class="metric">
        <div class="k">Speaking rate (overall)</div>
        <div class="v"><span id="wpm">0</span> <span class="small">WPM</span></div>
        <div class="s">Words / speaking-time</div>
      </div>

      <div class="metric">
        <div class="k">Total silence time (real-time)</div>
        <div class="v" id="silenceTotal">0.0s</div>
        <div class="s">Includes ongoing silence segments</div>
      </div>

      <div class="metric">
        <div class="k">Pause count</div>
        <div class="v" id="pauseCount">0</div>
        <div class="s">Silence ≥ min pause</div>
      </div>

      <div class="metric">
        <div class="k">Longest pause</div>
        <div class="v" id="pauseLongest">0.0s</div>
        <div class="s">Max silent segment ≥ min pause</div>
      </div>

      <div class="metric">
        <div class="k">Utterances</div>
        <div class="v" id="uttCount">0</div>
        <div class="s">Speaking bursts between pauses</div>
      </div>

      <div class="metric">
        <div class="k">Mean volume (speaking)</div>
        <div class="v"><span id="volMean">—</span> <span class="small">dB</span></div>
        <div class="s">Average dB while speaking</div>
      </div>

      <div class="metric">
        <div class="k">Volume variability</div>
        <div class="v"><span id="volStd">—</span> <span class="small">dB</span></div>
        <div class="s">Std dev while speaking</div>
      </div>

      <div class="metric">
        <div class="k">Mean pitch (speaking)</div>
        <div class="v"><span id="pitchMean">—</span> <span class="small">Hz</span></div>
        <div class="s">Average pitch while speaking</div>
      </div>

      <div class="metric">
        <div class="k">Pitch variability</div>
        <div class="v"><span id="pitchStd">—</span> <span class="small">Hz</span></div>
        <div class="s">Std dev while speaking</div>
      </div>

      <div class="metric" style="grid-column:1 / -1">
        <div class="k">Filler words (English heuristic)</div>
        <div class="v"><span id="fillers">0</span> <span class="small">(um/uh/like/you know…)</span></div>
        <div class="s">Edit list in code as needed</div>
      </div>
    </div>

    <div class="hr"></div>

    <div class="panelTitle">Pause distribution (seconds)</div>
    <div class="hist" id="pauseHist"></div>

    <div class="hr"></div>

    <div class="panelTitle">Utterances (segmented by pauses)</div>
    <div class="scroll">
      <table aria-label="utterance table">
        <thead>
          <tr>
            <th style="width:58px;">#</th>
            <th style="width:90px;">Start</th>
            <th style="width:90px;">End</th>
            <th style="width:80px;">Dur</th>
            <th style="width:70px;">Words</th>
            <th>Text (final, best-effort)</th>
          </tr>
        </thead>
        <tbody id="uttBody"></tbody>
      </table>
    </div>

    <div class="hr"></div>

    <div class="small">
      <div class="mono">Export:</div>
      <div class="row" style="margin-top:8px">
        <button id="btnCopy">Copy transcript</button>
        <button id="btnJson">Download session JSON</button>
      </div>
    </div>
  </aside>
</main>

<div class="footer">
  Implementation: utterance text is derived from final transcript word deltas; if SpeechRecognition batches late, boundaries may be approximate.
</div>

<script>
(() => {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  const hasSpeech = !!SpeechRecognition;
  const hasAudio = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);

  const el = (id) => document.getElementById(id);

  const btnStart = el("btnStart");
  const btnStop  = el("btnStop");
  const btnReset = el("btnReset");
  const btnCopy  = el("btnCopy");
  const btnJson  = el("btnJson");

  const statusDot = el("statusDot");
  const statusText = el("statusText");

  const transcriptEl = el("transcript");
  const langEl = el("lang");
  const silenceDbEl = el("silenceDb");
  const minPauseMsEl = el("minPauseMs");
  const rollWinSecEl = el("rollWinSec");

  const elapsedEl = el("elapsed");
  const wordsEl = el("words");
  const wpmEl = el("wpm");
  const rollingWpmEl = el("rollingWpm");
  const silenceTotalEl = el("silenceTotal");
  const pauseCountEl = el("pauseCount");
  const pauseLongestEl = el("pauseLongest");
  const uttCountEl = el("uttCount");

  const volDbEl = el("volDb");
  const volBarEl = el("volBar");
  const pitchHzEl = el("pitchHz");
  const pitchBarEl = el("pitchBar");
  const rollBarEl = el("rollBar");

  const volMeanEl = el("volMean");
  const volStdEl = el("volStd");
  const pitchMeanEl = el("pitchMean");
  const pitchStdEl = el("pitchStd");
  const fillersEl = el("fillers");

  const pauseHistEl = el("pauseHist");
  const uttBodyEl = el("uttBody");

  if (!hasSpeech) alert("SpeechRecognition not supported in this browser. Try Chrome/Edge.");
  if (!hasAudio) alert("getUserMedia not supported in this browser.");

  // ----------------------------
  // State
  // ----------------------------
  let running = false;

  // Transcription
  let recognition = null;
  let finalTranscript = "";
  let interimTranscript = "";

  // Timing
  let t0 = 0;
  let rafId = null;

  // Audio
  let audioCtx = null;
  let mediaStream = null;
  let sourceNode = null;
  let analyser = null;
  let timeDomain = null;

  // Controls
  let silenceThresholdDb = -45;
  let minPauseMs = 300;
  let rollWinSec = 10;

  // Silence / pause tracking
  let isSilent = true;
  let silentStart = null;           // perf timestamp for current silent segment start
  let totalSilenceMs = 0;           // completed silent segments (real-time adds current segment)
  let pauseCount = 0;
  let longestPauseMs = 0;
  const pauseDurationsMs = [];

  // Speaking time
  let totalSpeakingMs = 0;

  // Aggregate stats (speaking-only)
  const makeWelford = () => ({ n: 0, mean: 0, m2: 0 });
  const welfordUpdate = (w, x) => {
    w.n += 1;
    const delta = x - w.mean;
    w.mean += delta / w.n;
    const delta2 = x - w.mean;
    w.m2 += delta * delta2;
  };
  const welfordStd = (w) => (w.n > 1 ? Math.sqrt(w.m2 / (w.n - 1)) : 0);

  let volStats = makeWelford();
  let pitchStats = makeWelford();

  // Timeline export
  const samples = [];
  let lastLoopPerf = 0;
  let lastSamplePerf = 0;

  // Rolling WPM word events
  const wordEvents = [];

  // Utterances
  const utterances = [];
  let currentUtt = null;
  function newUttStats() { return { vol: makeWelford(), pitch: makeWelford() }; }
  let assignedFinalWords = 0;

  // Filler words heuristic
  const fillerList = [
    "um","uh","erm","like","you know","i mean","sort of","kind of","actually","basically","literally"
  ];

  // Pause distribution bins (seconds)
  const pauseBins = [
    { label: "0.3–0.5", lo: 0.3, hi: 0.5, count: 0 },
    { label: "0.5–1",   lo: 0.5, hi: 1.0, count: 0 },
    { label: "1–2",     lo: 1.0, hi: 2.0, count: 0 },
    { label: "2–4",     lo: 2.0, hi: 4.0, count: 0 },
    { label: "4–8",     lo: 4.0, hi: 8.0, count: 0 },
    { label: "8+",      lo: 8.0, hi: Infinity, count: 0 }
  ];

  // ----------------------------
  // Helpers
  // ----------------------------
  const clamp = (v, a, b) => Math.max(a, Math.min(b, v));
  const fmt1 = (x) => (Number.isFinite(x) ? x.toFixed(1) : "—");
  const fmt0 = (x) => (Number.isFinite(x) ? Math.round(x).toString() : "—");

  function setStatus(mode) {
    statusDot.classList.remove("on","warn","bad");
    if (mode === "running") statusDot.classList.add("on");
    else if (mode === "listening") statusDot.classList.add("warn");
    else if (mode === "error") statusDot.classList.add("bad");
    statusText.textContent = mode;
  }

  function formatElapsed(ms) {
    const s = ms / 1000;
    const mm = Math.floor(s / 60);
    const ss = Math.floor(s % 60);
    const t = (s - Math.floor(s)).toFixed(1).slice(1);
    return `${String(mm).padStart(2,"0")}:${String(ss).padStart(2,"0")}${t}`;
  }

  function countWords(text) {
    const cleaned = text.replace(/\s+/g, " ").trim();
    if (!cleaned) return 0;
    return cleaned.split(" ").filter(Boolean).length;
  }

  function countFillers(textLower) {
    let count = 0;
    for (const f of fillerList) {
      const re = new RegExp(`\\b${f.replace(/[.*+?^${}()|[\]\\]/g, "\\$&")}\\b`, "g");
      const m = textLower.match(re);
      if (m) count += m.length;
    }
    return count;
  }

  function rmsDb(buf) {
    let sum = 0;
    for (let i = 0; i < buf.length; i++) {
      const x = buf[i];
      sum += x * x;
    }
    const rms = Math.sqrt(sum / buf.length);
    return 20 * Math.log10(Math.max(rms, 1e-8));
  }

  function estimatePitchHz(buf, sampleRate) {
    let mean = 0;
    for (let i = 0; i < buf.length; i++) mean += buf[i];
    mean /= buf.length;

    const x = new Float32Array(buf.length);
    for (let i = 0; i < buf.length; i++) x[i] = buf[i] - mean;

    let e = 0;
    for (let i = 0; i < x.length; i++) e += x[i] * x[i];
    e /= x.length;
    if (e < 1e-5) return null;

    const minHz = 50, maxHz = 400;
    const minLag = Math.floor(sampleRate / maxHz);
    const maxLag = Math.floor(sampleRate / minHz);

    let bestLag = -1;
    let bestVal = 0;

    for (let lag = minLag; lag <= maxLag; lag++) {
      let c = 0;
      for (let i = 0; i < x.length - lag; i++) c += x[i] * x[i + lag];
      if (c > bestVal) { bestVal = c; bestLag = lag; }
    }
    if (bestLag <= 0) return null;

    let zero = 0;
    for (let i = 0; i < x.length; i++) zero += x[i] * x[i];
    const conf = bestVal / Math.max(zero, 1e-8);
    if (conf < 0.2) return null;

    return sampleRate / bestLag;
  }

  function resetPauseBins() { for (const b of pauseBins) b.count = 0; }
  function addPauseToBins(ms) {
    const s = ms / 1000;
    for (const b of pauseBins) {
      if (s >= b.lo && s < b.hi) { b.count += 1; return; }
    }
  }

  function renderPauseHistogram() {
    pauseHistEl.innerHTML = "";
    const max = Math.max(1, ...pauseBins.map(b => b.count));
    for (const b of pauseBins) {
      const row = document.createElement("div");
      row.className = "histRow";

      const lab = document.createElement("div");
      lab.className = "small mono";
      lab.textContent = b.label + "s";

      const bar = document.createElement("div");
      bar.className = "histBar";
      const fill = document.createElement("div");
      fill.style.width = `${Math.round((b.count / max) * 100)}%`;
      bar.appendChild(fill);

      const num = document.createElement("div");
      num.className = "small mono";
      num.style.textAlign = "right";
      num.textContent = String(b.count);

      row.appendChild(lab);
      row.appendChild(bar);
      row.appendChild(num);
      pauseHistEl.appendChild(row);
    }
  }

  function renderUtterancesTable() {
    uttBodyEl.innerHTML = "";
    for (const u of utterances) {
      const tr = document.createElement("tr");
      const td = (txt, cls="") => {
        const c = document.createElement("td");
        if (cls) c.className = cls;
        c.textContent = txt;
        return c;
      };
      tr.appendChild(td(String(u.id), "mono"));
      tr.appendChild(td(formatElapsed(u.start_ms), "mono"));
      tr.appendChild(td(formatElapsed(u.end_ms), "mono"));
      tr.appendChild(td(`${(u.dur_ms/1000).toFixed(1)}s`, "mono"));
      tr.appendChild(td(String(u.words), "mono"));
      tr.appendChild(td(u.text || ""));
      uttBodyEl.appendChild(tr);
    }
    uttCountEl.textContent = String(utterances.length);
  }

  function openNewUtterance(startMs) {
    currentUtt = {
      id: utterances.length + 1,
      start_ms: startMs,
      end_ms: null,
      dur_ms: null,
      words: 0,
      text: "",
      stats: newUttStats()
    };
  }

  function closeCurrentUtterance(endMs) {
    if (!currentUtt) return;

    currentUtt.end_ms = endMs;
    currentUtt.dur_ms = Math.max(0, currentUtt.end_ms - currentUtt.start_ms);

    const allWords = finalTranscript.replace(/\s+/g, " ").trim().split(" ").filter(Boolean);
    const newWords = allWords.slice(assignedFinalWords);
    currentUtt.words = newWords.length;
    currentUtt.text = newWords.join(" ");
    assignedFinalWords = allWords.length;

    const v = currentUtt.stats.vol;
    const p = currentUtt.stats.pitch;
    currentUtt.vol_mean_db = v.n ? v.mean : null;
    currentUtt.vol_std_db  = v.n ? welfordStd(v) : null;
    currentUtt.pitch_mean_hz = p.n ? p.mean : null;
    currentUtt.pitch_std_hz  = p.n ? welfordStd(p) : null;

    delete currentUtt.stats;

    utterances.push(currentUtt);
    currentUtt = null;
    renderUtterancesTable();
  }

  function updateOverallWPM() {
    const words = countWords(finalTranscript);
    const speakingMin = Math.max(totalSpeakingMs / 60000, 1e-6);
    const wpm = words / speakingMin;
    wpmEl.textContent = fmt0(wpm);
  }

  function updateRollingWPM(elapsedMs) {
    rollWinSec = Math.max(1, Number(rollWinSecEl.value) || 10);
    const winMs = rollWinSec * 1000;
    const cutoff = elapsedMs - winMs;

    while (wordEvents.length && wordEvents[0].t_ms < cutoff) wordEvents.shift();

    const wordsInWindow = wordEvents.reduce((a, e) => a + e.count, 0);
    const wpm = (wordsInWindow / rollWinSec) * 60;
    rollingWpmEl.textContent = fmt0(wpm);

    const norm = clamp(wpm / 200, 0, 1);
    rollBarEl.style.width = `${Math.round(norm * 100)}%`;
  }

  function updateAggregateDisplays(realtimeSilenceMs) {
    if (volStats.n > 0) {
      volMeanEl.textContent = fmt1(volStats.mean);
      volStdEl.textContent = fmt1(welfordStd(volStats));
    } else { volMeanEl.textContent = "—"; volStdEl.textContent = "—"; }

    if (pitchStats.n > 0) {
      pitchMeanEl.textContent = fmt0(pitchStats.mean);
      pitchStdEl.textContent = fmt0(welfordStd(pitchStats));
    } else { pitchMeanEl.textContent = "—"; pitchStdEl.textContent = "—"; }

    // ✅ real-time silence
    silenceTotalEl.textContent = `${(realtimeSilenceMs / 1000).toFixed(1)}s`;

    pauseCountEl.textContent = String(pauseCount);
    pauseLongestEl.textContent = `${(longestPauseMs / 1000).toFixed(1)}s`;

    wordsEl.textContent = String(countWords(finalTranscript));
    fillersEl.textContent = String(countFillers(finalTranscript.toLowerCase()));

    uttCountEl.textContent = String(utterances.length + (currentUtt ? 1 : 0));
  }

  function realtimeSilenceMs(nowPerf) {
    if (isSilent && silentStart !== null) return totalSilenceMs + (nowPerf - silentStart);
    return totalSilenceMs;
  }

  // ----------------------------
  // Speech recognition
  // ----------------------------
  function initRecognition() {
    if (!hasSpeech) return;

    recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = langEl.value;

    recognition.onstart = () => { if (running) setStatus("listening"); };

    recognition.onresult = (event) => {
      let interim = "";
      let appendedFinalText = "";

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const res = event.results[i];
        const text = res[0].transcript;
        if (res.isFinal) appendedFinalText += text + " ";
        else interim += text;
      }

      if (appendedFinalText) {
        const prevWords = countWords(finalTranscript);
        finalTranscript += appendedFinalText;
        const nextWords = countWords(finalTranscript);
        const delta = Math.max(0, nextWords - prevWords);
        const t_ms = Math.max(0, performance.now() - t0);
        if (delta > 0) wordEvents.push({ t_ms, count: delta });
      }

      interimTranscript = interim;
      transcriptEl.value = (finalTranscript + "\n" + interimTranscript).trim();
    };

    recognition.onerror = (e) => { console.warn("SpeechRecognition error:", e); setStatus("error"); };

    recognition.onend = () => {
      if (running) { try { recognition.start(); } catch (_) {} }
      else setStatus("idle");
    };
  }

  function startRecognition() {
    if (!recognition) initRecognition();
    recognition.lang = langEl.value;
    try { recognition.start(); } catch (e) { console.warn(e); }
  }

  function stopRecognition() {
    if (!recognition) return;
    try { recognition.onend = null; recognition.stop(); } catch (_) {}
    initRecognition();
  }

  // ----------------------------
  // Audio
  // ----------------------------
  async function initAudio() {
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    mediaStream = await navigator.mediaDevices.getUserMedia({
      audio: { echoCancellation:true, noiseSuppression:true, autoGainControl:false }
    });
    sourceNode = audioCtx.createMediaStreamSource(mediaStream);
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 2048;
    analyser.smoothingTimeConstant = 0.2;
    sourceNode.connect(analyser);
    timeDomain = new Float32Array(analyser.fftSize);
  }

  function stopAudio() {
    if (mediaStream) { mediaStream.getTracks().forEach(t => t.stop()); mediaStream = null; }
    if (audioCtx) { audioCtx.close().catch(()=>{}); audioCtx = null; }
    sourceNode = null; analyser = null; timeDomain = null;
  }

  // ----------------------------
  // Main loop
  // ----------------------------
  function loop(ts) {
    if (!running) return;

    const elapsed = ts - t0;
    elapsedEl.textContent = formatElapsed(elapsed);

    silenceThresholdDb = Number(silenceDbEl.value);
    minPauseMs = Number(minPauseMsEl.value);

    if (analyser && timeDomain && audioCtx) {
      analyser.getFloatTimeDomainData(timeDomain);

      const db = rmsDb(timeDomain);
      volDbEl.textContent = fmt1(db);

      const volNorm = clamp((db - (-60)) / 50, 0, 1);
      volBarEl.style.width = `${Math.round(volNorm * 100)}%`;

      const nowPerf = performance.now();
      const dt = (lastLoopPerf > 0) ? (nowPerf - lastLoopPerf) : 0;
      lastLoopPerf = nowPerf;

      const currentlySilent = (db < silenceThresholdDb);

      // Pitch
      let pitch = null;
      if (!currentlySilent) pitch = estimatePitchHz(timeDomain, audioCtx.sampleRate);

      if (pitch && Number.isFinite(pitch)) {
        pitchHzEl.textContent = fmt0(pitch);
        const pitchNorm = clamp((pitch - 50) / 350, 0, 1);
        pitchBarEl.style.width = `${Math.round(pitchNorm * 100)}%`;
      } else {
        pitchHzEl.textContent = "—";
        pitchBarEl.style.width = "0%";
      }

      // Speaking time + stats + utterance open
      if (dt > 0 && !currentlySilent) {
        totalSpeakingMs += dt;

        welfordUpdate(volStats, db);
        if (pitch && Number.isFinite(pitch)) welfordUpdate(pitchStats, pitch);

        if (!currentUtt) openNewUtterance(elapsed);
        welfordUpdate(currentUtt.stats.vol, db);
        if (pitch && Number.isFinite(pitch)) welfordUpdate(currentUtt.stats.pitch, pitch);
      }

      // Silence transitions
      if (currentlySilent && !isSilent) {
        isSilent = true;
        silentStart = nowPerf;
      } else if (!currentlySilent && isSilent) {
        isSilent = false;

        if (silentStart !== null) {
          const silentDur = nowPerf - silentStart;
          totalSilenceMs += silentDur;

          if (silentDur >= minPauseMs) {
            pauseCount += 1;
            pauseDurationsMs.push(silentDur);
            longestPauseMs = Math.max(longestPauseMs, silentDur);
            addPauseToBins(silentDur);
            renderPauseHistogram();

            closeCurrentUtterance(Math.max(0, elapsed - silentDur));
          }
          silentStart = null;
        }
      }

      // ✅ real-time silence update every frame
      const rtSilence = realtimeSilenceMs(nowPerf);

      // Rolling + overall rates
      updateRollingWPM(elapsed);
      updateOverallWPM();

      // Downsample timeline (~4 Hz)
      if (nowPerf - lastSamplePerf >= 250) {
        samples.push({
          t_ms: Math.round(elapsed),
          volume_db: Number(db.toFixed(2)),
          pitch_hz: pitch ? Math.round(pitch) : null,
          is_silent: currentlySilent,
          total_silence_s_realtime: Number((rtSilence / 1000).toFixed(2))
        });
        lastSamplePerf = nowPerf;
      }

      updateAggregateDisplays(rtSilence);
    }

    rafId = requestAnimationFrame(loop);
  }

  // ----------------------------
  // Start/Stop/Reset
  // ----------------------------
  async function start() {
    if (running) return;

    isSilent = true;
    silentStart = null;
    lastLoopPerf = 0;
    lastSamplePerf = 0;

    try { await initAudio(); }
    catch (e) { console.error(e); alert("Microphone access failed. Allow mic permissions and try again."); return; }

    if (hasSpeech) { initRecognition(); startRecognition(); }
    else alert("SpeechRecognition not supported. Audio metrics will still run.");

    running = true;
    t0 = performance.now();
    setStatus("running");

    btnStart.disabled = true;
    btnStop.disabled = false;

    rafId = requestAnimationFrame(loop);
  }

  function stop() {
    if (!running) return;
    running = false;

    const nowPerf = performance.now();
    const elapsed = nowPerf - t0;

    // finalize ongoing silence segment
    if (isSilent && silentStart !== null) {
      const silentDur = nowPerf - silentStart;
      totalSilenceMs += silentDur;

      if (silentDur >= minPauseMs) {
        pauseCount += 1;
        pauseDurationsMs.push(silentDur);
        longestPauseMs = Math.max(longestPauseMs, silentDur);
        addPauseToBins(silentDur);
      }
      silentStart = null;
    }

    // close ongoing utterance
    if (currentUtt) closeCurrentUtterance(elapsed);

    if (rafId) cancelAnimationFrame(rafId);
    rafId = null;

    stopRecognition();
    stopAudio();

    setStatus("idle");
    btnStart.disabled = false;
    btnStop.disabled = true;

    renderPauseHistogram();
    renderUtterancesTable();
    updateOverallWPM();

    // final silence display
    silenceTotalEl.textContent = `${(totalSilenceMs / 1000).toFixed(1)}s`;
  }

  function resetAll() {
    stop();

    finalTranscript = "";
    interimTranscript = "";
    transcriptEl.value = "";

    totalSilenceMs = 0;
    pauseCount = 0;
    longestPauseMs = 0;
    pauseDurationsMs.length = 0;
    resetPauseBins();
    renderPauseHistogram();

    totalSpeakingMs = 0;
    volStats = makeWelford();
    pitchStats = makeWelford();

    samples.length = 0;
    wordEvents.length = 0;
    utterances.length = 0;
    currentUtt = null;
    assignedFinalWords = 0;

    volDbEl.textContent = "—";
    volBarEl.style.width = "0%";
    pitchHzEl.textContent = "—";
    pitchBarEl.style.width = "0%";
    rollBarEl.style.width = "0%";

    elapsedEl.textContent = "00:00.0";
    wordsEl.textContent = "0";
    wpmEl.textContent = "0";
    rollingWpmEl.textContent = "0";
    silenceTotalEl.textContent = "0.0s";
    pauseCountEl.textContent = "0";
    pauseLongestEl.textContent = "0.0s";
    uttCountEl.textContent = "0";
    volMeanEl.textContent = "—";
    volStdEl.textContent = "—";
    pitchMeanEl.textContent = "—";
    pitchStdEl.textContent = "—";
    fillersEl.textContent = "0";

    renderUtterancesTable();
    setStatus("idle");
  }

  // ----------------------------
  // Export
  // ----------------------------
  function copyTranscript() {
    const text = finalTranscript.trim();
    navigator.clipboard.writeText(text).then(() => {
      btnCopy.textContent = "Copied!";
      setTimeout(() => btnCopy.textContent = "Copy transcript", 900);
    }).catch(() => alert("Copy failed (browser permissions)."));
  }

  function downloadJson() {
    const pausesSec = pauseDurationsMs.map(ms => ms/1000);
    const pauseMean = pausesSec.length ? pausesSec.reduce((a,b)=>a+b,0)/pausesSec.length : null;

    const payload = {
      exported_at: new Date().toISOString(),
      config: {
        language: langEl.value,
        silence_threshold_db: Number(silenceDbEl.value),
        min_pause_ms: Number(minPauseMsEl.value),
        rolling_window_sec: Math.max(1, Number(rollWinSecEl.value) || 10)
      },
      transcript_final: finalTranscript.trim(),
      metrics: {
        words: countWords(finalTranscript),
        wpm_overall: Number(wpmEl.textContent) || 0,
        total_silence_s: totalSilenceMs / 1000,
        pause_count: pauseCount,
        pause_longest_s: longestPauseMs / 1000,
        pause_mean_s: pauseMean,
        utterances: utterances.length,
        volume_db_mean: volStats.n ? volStats.mean : null,
        volume_db_std:  volStats.n ? welfordStd(volStats) : null,
        pitch_hz_mean:  pitchStats.n ? pitchStats.mean : null,
        pitch_hz_std:   pitchStats.n ? welfordStd(pitchStats) : null,
        fillers: countFillers(finalTranscript.toLowerCase()),
        pause_bins: pauseBins.map(b => ({ label: b.label, count: b.count }))
      },
      utterance_segments: utterances,
      timeline_samples: samples
    };

    const blob = new Blob([JSON.stringify(payload, null, 2)], { type: "application/json" });
    const url = URL.createObjectURL(blob);
    const a = document.createElement("a");
    a.href = url;
    a.download = `speech_session_${Date.now()}.json`;
    document.body.appendChild(a);
    a.click();
    a.remove();
    URL.revokeObjectURL(url);
  }

  // ----------------------------
  // Wire up
  // ----------------------------
  btnStart.addEventListener("click", start);
  btnStop.addEventListener("click", stop);
  btnReset.addEventListener("click", resetAll);
  btnCopy.addEventListener("click", copyTranscript);
  btnJson.addEventListener("click", downloadJson);

  langEl.addEventListener("change", () => { if (recognition) recognition.lang = langEl.value; });

  // init
  resetPauseBins();
  renderPauseHistogram();
  renderUtterancesTable();
  setStatus("idle");
})();
</script>
</body>
</html>
